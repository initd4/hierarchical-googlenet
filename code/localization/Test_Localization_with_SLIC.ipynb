{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os, caffe, cv2, copy, cPickle, gzip\n",
    "from prettytable import PrettyTable\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (5, 5)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "caffe.set_mode_gpu()\n",
    "caffe.set_device(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_mean_file(path):\n",
    "    \n",
    "    blob_mean_file = caffe.proto.caffe_pb2.BlobProto()\n",
    "    mean_file = open(path, 'rb' ).read()\n",
    "    blob_mean_file.ParseFromString(mean_file)\n",
    "    mean_npy = np.array(caffe.io.blobproto_to_array(blob_mean_file)) # ASSUMED IN BGR\n",
    "    \n",
    "    return mean_npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "\n",
    "    img = cv2.imread(path, 1)\n",
    "\n",
    "    return img  \n",
    "\n",
    "\n",
    "def print_image(img_rescaled):\n",
    "\n",
    "    img_plt = copy.copy(img_rescaled)\n",
    "    channel_0 = copy.copy(img_plt[:, :, 0])\n",
    "    img_plt[:, :, 0] = img_plt[:, :, 2]\n",
    "    img_plt[:, :, 2] = channel_0 \n",
    "\n",
    "    plt.imshow(img_plt)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def rescale_image(img, scale = [256, 256]):\n",
    "\n",
    "    img_rescaled = cv2.resize(img, (scale[0], scale[1]), interpolation = cv2.INTER_LINEAR) # IMAGE IS BGR\n",
    "\n",
    "    return img_rescaled\n",
    "\n",
    "\n",
    "def convert_img_shape_for_caffe(img_rescaled):\n",
    "\n",
    "    caffe_img = np.expand_dims(img_rescaled.swapaxes(0, 2).swapaxes(1, 2), axis = 0)\n",
    "\n",
    "    return caffe_img\n",
    "\n",
    "\n",
    "def subtract_mean_from_image(caffe_img, mean_npy):\n",
    "\n",
    "    img_mean_subtracted = caffe_img.astype('float32') - mean_npy\n",
    "\n",
    "    return img_mean_subtracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_images(net, cropped_images):\n",
    "    \n",
    "    net.blobs['data'].data[...] = cropped_images\n",
    "    out = net.forward()\n",
    "    \n",
    "    #print(\"Predicted class is #{}.\".format(out['prob'][0].argmax()))\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_predictions(out, labels, top_n, out_key):\n",
    "\n",
    "    top_n_predictions = []\n",
    "    \n",
    "    predictions = out[out_key]\n",
    "    \n",
    "    for i in xrange(len(predictions)):\n",
    "    \n",
    "        predicted_indexes =  np.argsort(predictions[i])[-top_n:][::-1]\n",
    "        predicted_probabilities = predictions[i][predicted_indexes].reshape(-1, 1)\n",
    "        predicted_labels = labels[predicted_indexes].reshape(-1, 1)\n",
    "\n",
    "        top_n_predictions.append(np.concatenate((predicted_labels, predicted_probabilities), axis = 1))\n",
    "    \n",
    "    top_n_predictions = np.array(top_n_predictions)\n",
    "    \n",
    "    return top_n_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_predictions(top_n_predictions, title):\n",
    "    \n",
    "    prediction_table = PrettyTable(top_n_predictions.dtype.names)\n",
    "\n",
    "    for row in top_n_predictions:\n",
    "        prediction_table.add_row(row)\n",
    "\n",
    "    prediction_table.field_names = ['Predicted Class', 'Predicted Probability']\n",
    "\n",
    "    print '\\n--------------{}--------------'.format(title)\n",
    "    print prediction_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of predictions    : (3, 100000, 5, 2)\n",
      "Shape of crop positions : (100000, 2)\n"
     ]
    }
   ],
   "source": [
    "test_image_names_from_file = np.loadtxt('/home/nvidia/imagenet2015_onur/test/test_image_names.txt', dtype = 'str')\n",
    "\n",
    "#crop_positions_from_file = cPickle.load(gzip.open('./Test_Localization_SLIC_Outputs_oversegmented_sigma_5.pkl.gz'))\n",
    "crop_positions_from_file = cPickle.load(gzip.open('./Test_Localization_SLIC_Outputs.pkl.gz'))\n",
    "crop_positions_from_file = np.array(crop_positions_from_file)\n",
    "\n",
    "predictions_from_file = cPickle.load(gzip.open('./Test_Classification_25_crops_with_Scan_20151111-045327-bcce_resume_training_after_epoch_2_with_caffe-snapshot_iter_45921.caffemodel.pkl.gz'))\n",
    "\n",
    "print 'Shape of predictions    :', predictions_from_file.shape\n",
    "print 'Shape of crop positions :', crop_positions_from_file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_n = 5\n",
    "\n",
    "labels3 = np.loadtxt('/home/nvidia/imagenet2015_onur/level3_labels/labels.txt', dtype = 'str')\n",
    "labels2 = np.loadtxt('/home/nvidia/imagenet2015_onur/level2_labels/level_2_labels.txt', dtype = 'str')\n",
    "labels1 = np.loadtxt('/home/nvidia/imagenet2015_onur/level1_labels/level_1_labels.txt', dtype = 'str')\n",
    "\n",
    "node_names = np.loadtxt('../imagenet2015_onur/all_labels/constructed_labels.csv', dtype = 'str', delimiter = ',')\n",
    "node_names = node_names[:, [0, 2, 3]]\n",
    "node_names[:,[0, 1, 2]] = node_names[:,[1, 2, 0]]\n",
    "\n",
    "mean_npy = read_mean_file('/home/nvidia/imagenet_lmdb/mean.binaryproto')\n",
    "\n",
    "net = caffe.Net('/home/nvidia/digits-2.2/digits/jobs/20151105-150238-61f1/deploy_corrected.prototxt',\n",
    "                '/home/nvidia/digits-2.2/digits/jobs/20151111-045327-bcce_resume_training_after_epoch_2_with_caffe/snapshot_iter_45921.caffemodel',\n",
    "                caffe.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bboxes_for_all_images = []\n",
    "node_names_level3_for_all_images = []\n",
    "\n",
    "for __index in xrange(len(test_image_names_from_file)):\n",
    "    \n",
    "    if __index % 5000 == 0:\n",
    "        print 'Done :', __index\n",
    "    \n",
    "    img = read_image('../data/ILSVRC2015/Data/CLS-LOC/test/' + test_image_names_from_file[__index])\n",
    "    img_rescaled = rescale_image(img, scale = [256, 256])\n",
    "    caffe_img = convert_img_shape_for_caffe(img_rescaled)\n",
    "    img_mean_subtracted = subtract_mean_from_image(caffe_img, mean_npy)\n",
    "\n",
    "    crop_positions_for_an_image = np.array(crop_positions_from_file[__index][1])\n",
    "    predictions_for_an_image = predictions_from_file[:, __index]\n",
    "\n",
    "    #############-----------------new---------------------------------\n",
    "    node_names_for_an_image = []\n",
    "\n",
    "    for pfai in predictions_for_an_image[-1][:, 0]:\n",
    "        node_names_for_an_image.append(node_names[np.where(node_names[:, -1] == pfai)[0]][0])\n",
    "\n",
    "    node_names_for_an_image = np.array(node_names_for_an_image)\n",
    "    #############--------------------------------\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    cropped_mean_subtracted_images_for_an_image = []\n",
    "    cropped_rescaled_images_for_an_image = []\n",
    "\n",
    "    for cpfai in crop_positions_for_an_image:\n",
    "        _cropped = img_mean_subtracted[:, :, cpfai[0]:cpfai[1], cpfai[2]:cpfai[3]]\n",
    "        _cropped = np.squeeze(_cropped, axis = 0).swapaxes(0, 2).swapaxes(0, 1)\n",
    "\n",
    "        _cropped_rescaled = rescale_image(_cropped, scale = [224, 224])\n",
    "        _cropped_rescaled = _cropped_rescaled.swapaxes(0, 2).swapaxes(1, 2)\n",
    "\n",
    "        cropped_mean_subtracted_images_for_an_image.append(_cropped_rescaled)\n",
    "\n",
    "        cropped_rescaled_images_for_an_image.append(rescale_image(img_rescaled[cpfai[0]:cpfai[1], cpfai[2]:cpfai[3]], \n",
    "                                                                  scale = [224, 224]))\n",
    "\n",
    "    cropped_mean_subtracted_images_for_an_image = np.array(cropped_mean_subtracted_images_for_an_image)\n",
    "    cropped_rescaled_images_for_an_image = np.array(cropped_rescaled_images_for_an_image)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    net.blobs['data'].reshape(cropped_mean_subtracted_images_for_an_image.shape[0],\n",
    "                              cropped_mean_subtracted_images_for_an_image.shape[1],\n",
    "                              cropped_mean_subtracted_images_for_an_image.shape[2],\n",
    "                              cropped_mean_subtracted_images_for_an_image.shape[3])\n",
    "\n",
    "    caffe_output = classify_images(net, cropped_mean_subtracted_images_for_an_image)\n",
    "\n",
    "    top_n_predictions_level1 = get_predictions(caffe_output, labels1, top_n, 'prob1')\n",
    "    top_n_predictions_level2 = get_predictions(caffe_output, labels2, top_n, 'prob2')\n",
    "    top_n_predictions_level3 = get_predictions(caffe_output, labels3, top_n, 'prob3')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    node_names_for_level1 = np.array(list(set(node_names_for_an_image[:, 0])))\n",
    "    node_names_for_level2 = np.array(list(set(node_names_for_an_image[:, 1])))\n",
    "    node_names_for_level3 = np.array(list(set(node_names_for_an_image[:, 2])))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    crop_indexes_for_level1 = []\n",
    "\n",
    "    for i in xrange(len(node_names_for_level1)):\n",
    "\n",
    "        for k in xrange(5):\n",
    "\n",
    "            out_index = list(np.where(top_n_predictions_level1[:, k, 0] == node_names_for_level1[i])[0])\n",
    "\n",
    "            if out_index:\n",
    "                break\n",
    "\n",
    "        if not out_index:\n",
    "            out_index = None\n",
    "\n",
    "        crop_indexes_for_level1.append(out_index)\n",
    "\n",
    "    crop_indexes_for_level1 = np.array(crop_indexes_for_level1)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    parent_nodes_for_level2 = []\n",
    "\n",
    "    for i in xrange(len(node_names_for_level2)):\n",
    "        parent_nodes_for_level2.append(node_names_for_an_image[np.where(node_names_for_an_image[:, 1] == node_names_for_level2[i])[0]][:, 0][0])\n",
    "\n",
    "    parent_nodes_for_level2 = np.array(parent_nodes_for_level2)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    crop_indexes_for_level2 = []\n",
    "\n",
    "    for i in xrange(len(node_names_for_level2)):\n",
    "\n",
    "        avaliable_crops = crop_indexes_for_level1[np.where(node_names_for_level1 == parent_nodes_for_level2[i])[0]][0]\n",
    "\n",
    "        if avaliable_crops != None:\n",
    "\n",
    "            avaliable_crops_numpy = np.array(avaliable_crops)\n",
    "\n",
    "            for k in xrange(5):\n",
    "\n",
    "                out_index = list(np.where(top_n_predictions_level2[avaliable_crops_numpy, k, 0] == node_names_for_level2[i])[0])\n",
    "\n",
    "                if out_index:\n",
    "                    out_index = list(avaliable_crops_numpy[out_index])\n",
    "                    break\n",
    "\n",
    "            if not out_index:\n",
    "                out_index = None\n",
    "\n",
    "        if avaliable_crops == None or out_index == None:\n",
    "\n",
    "            for k in xrange(5):\n",
    "\n",
    "                out_index = list(np.where(top_n_predictions_level2[:, k, 0] == node_names_for_level2[i])[0])\n",
    "\n",
    "                if out_index:\n",
    "                    break\n",
    "\n",
    "            if not out_index:\n",
    "                out_index = None\n",
    "\n",
    "        crop_indexes_for_level2.append(out_index)\n",
    "\n",
    "    crop_indexes_for_level2 = np.array(crop_indexes_for_level2)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    parent_nodes_for_level3 = []\n",
    "\n",
    "    for i in xrange(len(node_names_for_level3)):\n",
    "        parent_nodes_for_level3.append(node_names_for_an_image[np.where(node_names_for_an_image[:, 2] == node_names_for_level3[i])[0]][:, 1][0])\n",
    "\n",
    "    parent_nodes_for_level3 = np.array(parent_nodes_for_level3)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    crop_indexes_for_level3 = []\n",
    "\n",
    "    for i in xrange(len(node_names_for_level3)):\n",
    "\n",
    "        avaliable_crops = crop_indexes_for_level2[np.where(node_names_for_level2 == parent_nodes_for_level3[i])[0]][0]\n",
    "\n",
    "        if avaliable_crops != None:\n",
    "\n",
    "            avaliable_crops_numpy = np.array(avaliable_crops)\n",
    "\n",
    "            for k in xrange(5):\n",
    "\n",
    "                out_index = list(np.where(top_n_predictions_level3[avaliable_crops_numpy, k, 0] == node_names_for_level3[i])[0])\n",
    "\n",
    "                if out_index:\n",
    "                    out_index = list(avaliable_crops_numpy[out_index])\n",
    "                    break\n",
    "\n",
    "            if not out_index:\n",
    "                out_index = None\n",
    "\n",
    "        if avaliable_crops == None or out_index == None:\n",
    "\n",
    "            nnfl1 = parent_nodes_for_level2[np.where(node_names_for_level2 == parent_nodes_for_level3[i])[0]]\n",
    "\n",
    "            avaliable_crops = crop_indexes_for_level1[np.where(node_names_for_level1 == nnfl1)[0]][0]\n",
    "\n",
    "            if avaliable_crops != None:\n",
    "\n",
    "                avaliable_crops_numpy = np.array(avaliable_crops)\n",
    "\n",
    "                for k in xrange(5):\n",
    "\n",
    "                    out_index = list(np.where(top_n_predictions_level3[avaliable_crops_numpy, k, 0] == node_names_for_level3[i])[0])\n",
    "\n",
    "                    if out_index:\n",
    "                        out_index = list(avaliable_crops_numpy[out_index])\n",
    "                        break\n",
    "\n",
    "                if not out_index:\n",
    "                    out_index = None\n",
    "\n",
    "            if avaliable_crops == None or out_index == None:\n",
    "\n",
    "                for k in xrange(5):\n",
    "\n",
    "                    out_index = list(np.where(top_n_predictions_level3[:, k, 0] == node_names_for_level3[i])[0])\n",
    "\n",
    "                    if out_index:\n",
    "                        break\n",
    "\n",
    "                if not out_index:\n",
    "                    out_index = None\n",
    "\n",
    "        crop_indexes_for_level3.append(out_index)\n",
    "\n",
    "    crop_indexes_for_level3 = np.array(crop_indexes_for_level3)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    predicted_bounding_boxes_for_an_image = []\n",
    "\n",
    "    for i in xrange(len(crop_indexes_for_level3)):\n",
    "\n",
    "        if crop_indexes_for_level3[i] is not None:\n",
    "            bbox = list(np.round(np.mean(crop_positions_for_an_image[crop_indexes_for_level3[i]], axis = 0)).astype('int'))\n",
    "           \n",
    "        else:\n",
    "            bbox = None\n",
    "\n",
    "        predicted_bounding_boxes_for_an_image.append(bbox)\n",
    "\n",
    "    #predicted_bounding_boxes_for_an_image = np.array(predicted_bounding_boxes_for_an_image)\n",
    "\n",
    "\n",
    "    bboxes_for_all_images.append(predicted_bounding_boxes_for_an_image)\n",
    "    node_names_level3_for_all_images.append(node_names_for_level3)\n",
    "    \n",
    "    \n",
    "#bboxes_for_all_images = np.array(bboxes_for_all_images)\n",
    "node_names_level3_for_all_images = np.array(node_names_level3_for_all_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#node_names_level3_for_all_images\n",
    "#bboxes_for_all_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, [29, 250, 2, 221], [139, 244, 3, 144], [44, 216, 67, 237], [166, 254, 132, 254]]\n",
      "['conch' 'eel' 'slug' 'banana' 'fig']\n"
     ]
    }
   ],
   "source": [
    "print bboxes_for_all_images[1]\n",
    "print node_names_level3_for_all_images[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = gzip.open('./Test_Localization_Segment_Bounding_Boxes_with_SLIC_New_Procedure_with_LOC-Test_Localization_SLIC_Outputs-and-CLS-Test_Classification_25_crops_with_Scan_20151111-045327-bcce_resume_training_after_epoch_2_with_caffe-snapshot_iter_45921.caffemodel.pkl.gz', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cPickle.dump((node_names_level3_for_all_images, bboxes_for_all_images), f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__index = 82552 #82152 #62132 #64278\n",
    "\n",
    "img = read_image('../data/ILSVRC2015/Data/CLS-LOC/test/' + test_image_names_from_file[__index])\n",
    "img_rescaled = rescale_image(img, scale = [256, 256])\n",
    "caffe_img = convert_img_shape_for_caffe(img_rescaled)\n",
    "img_mean_subtracted = subtract_mean_from_image(caffe_img, mean_npy)\n",
    "\n",
    "#print_image(img_rescaled)\n",
    "\n",
    "crop_positions_for_an_image = np.array(crop_positions_from_file[__index][1])\n",
    "predictions_for_an_image = predictions_from_file[:, __index]\n",
    "\n",
    "#############-----------------new---------------------------------\n",
    "node_names_for_an_image = []\n",
    "\n",
    "for pfai in predictions_for_an_image[-1][:, 0]:\n",
    "    node_names_for_an_image.append(node_names[np.where(node_names[:, -1] == pfai)[0]][0])\n",
    "    \n",
    "node_names_for_an_image = np.array(node_names_for_an_image)\n",
    "#############--------------------------------\n",
    "\n",
    "#print 'Number of crops :\\n\\n', len(crop_positions_for_an_image), '\\n\\n--------------\\n'\n",
    "#print 'Predictions     :\\n\\n', predictions_for_an_image, '\\n\\n--------------\\n'\n",
    "############----------------------new-----------------------\n",
    "#print 'Node names      :\\n\\n', node_names_for_an_image, '\\n\\n--------------\\n'\n",
    "############--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cropped_mean_subtracted_images_for_an_image = []\n",
    "cropped_rescaled_images_for_an_image = []\n",
    "\n",
    "for cpfai in crop_positions_for_an_image:\n",
    "    _cropped = img_mean_subtracted[:, :, cpfai[0]:cpfai[1], cpfai[2]:cpfai[3]]\n",
    "    _cropped = np.squeeze(_cropped, axis = 0).swapaxes(0, 2).swapaxes(0, 1)\n",
    "    \n",
    "    _cropped_rescaled = rescale_image(_cropped, scale = [224, 224])\n",
    "    _cropped_rescaled = _cropped_rescaled.swapaxes(0, 2).swapaxes(1, 2)\n",
    "    \n",
    "    cropped_mean_subtracted_images_for_an_image.append(_cropped_rescaled)\n",
    "    \n",
    "    cropped_rescaled_images_for_an_image.append(rescale_image(img_rescaled[cpfai[0]:cpfai[1], cpfai[2]:cpfai[3]], \n",
    "                                                              scale = [224, 224]))\n",
    "    \n",
    "cropped_mean_subtracted_images_for_an_image = np.array(cropped_mean_subtracted_images_for_an_image)\n",
    "cropped_rescaled_images_for_an_image = np.array(cropped_rescaled_images_for_an_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print 'Cropped Rescaled Images For an Image Shape        :', cropped_rescaled_images_for_an_image.shape\n",
    "#print 'Cropped Mean Subtracted Images For an Image Shape :', cropped_mean_subtracted_images_for_an_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.blobs['data'].reshape(cropped_mean_subtracted_images_for_an_image.shape[0],\n",
    "                          cropped_mean_subtracted_images_for_an_image.shape[1],\n",
    "                          cropped_mean_subtracted_images_for_an_image.shape[2],\n",
    "                          cropped_mean_subtracted_images_for_an_image.shape[3])\n",
    "\n",
    "caffe_output = classify_images(net, cropped_mean_subtracted_images_for_an_image)\n",
    "\n",
    "top_n_predictions_level1 = get_predictions(caffe_output, labels1, top_n, 'prob1')\n",
    "top_n_predictions_level2 = get_predictions(caffe_output, labels2, top_n, 'prob2')\n",
    "top_n_predictions_level3 = get_predictions(caffe_output, labels3, top_n, 'prob3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "node_names_for_level1 = np.array(list(set(node_names_for_an_image[:, 0])))\n",
    "node_names_for_level2 = np.array(list(set(node_names_for_an_image[:, 1])))\n",
    "node_names_for_level3 = np.array(list(set(node_names_for_an_image[:, 2])))\n",
    "\n",
    "#print node_names_for_level1\n",
    "#print node_names_for_level2\n",
    "#print node_names_for_level3\n",
    "#print '---------------------------'\n",
    "#print node_names_for_an_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crop_indexes_for_level1 = []\n",
    "\n",
    "for i in xrange(len(node_names_for_level1)):\n",
    "    \n",
    "    #print '\\n------- LABEL : {}'.format(node_names_for_level1[i])\n",
    "    \n",
    "    for k in xrange(5):\n",
    "        \n",
    "        out_index = list(np.where(top_n_predictions_level1[:, k, 0] == node_names_for_level1[i])[0])\n",
    "        \n",
    "        if out_index:\n",
    "            #print '\\nSelected : {}'.format(k)\n",
    "            break\n",
    "        \n",
    "    if not out_index:\n",
    "        out_index = None\n",
    "        \n",
    "    #print '\\nCrop Indexes for {} :'.format(node_names_for_level1[i]), out_index\n",
    "            \n",
    "    crop_indexes_for_level1.append(out_index)\n",
    "        \n",
    "crop_indexes_for_level1 = np.array(crop_indexes_for_level1)\n",
    "\n",
    "#print '\\n--------------------------------------------------------------------------------------\\n'\n",
    "#print '\\n------------- Selected Labels for Level 1\\n\\n', node_names_for_level1\n",
    "#print '\\n------------- Crop Indexes For Level 1:\\n\\n', crop_indexes_for_level1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parent_nodes_for_level2 = []\n",
    "\n",
    "for i in xrange(len(node_names_for_level2)):\n",
    "    parent_nodes_for_level2.append(node_names_for_an_image[np.where(node_names_for_an_image[:, 1] == node_names_for_level2[i])[0]][:, 0][0])\n",
    "    \n",
    "parent_nodes_for_level2 = np.array(parent_nodes_for_level2)\n",
    "\n",
    "#print '\\nParent nodes for level2 :', parent_nodes_for_level2\n",
    "#print '\\nNode names for level2   :', node_names_for_level2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crop_indexes_for_level2 = []\n",
    "\n",
    "for i in xrange(len(node_names_for_level2)):\n",
    "    \n",
    "    #print '\\n------- LABEL : {}'.format(node_names_for_level2[i])\n",
    "    \n",
    "    avaliable_crops = crop_indexes_for_level1[np.where(node_names_for_level1 == parent_nodes_for_level2[i])[0]][0]\n",
    "    \n",
    "    if avaliable_crops != None:\n",
    "        \n",
    "        avaliable_crops_numpy = np.array(avaliable_crops)\n",
    "    \n",
    "        #print '\\nAvaliable crops for {} :'.format(node_names_for_level2[i]), avaliable_crops_numpy\n",
    "\n",
    "        for k in xrange(5):\n",
    "\n",
    "            out_index = list(np.where(top_n_predictions_level2[avaliable_crops_numpy, k, 0] == node_names_for_level2[i])[0])\n",
    "\n",
    "            if out_index:\n",
    "                out_index = list(avaliable_crops_numpy[out_index])\n",
    "                #print '\\nSelected : {}'.format(k)\n",
    "                break\n",
    "\n",
    "        if not out_index:\n",
    "            out_index = None\n",
    "            \n",
    "    if avaliable_crops == None or out_index == None:\n",
    "        \n",
    "        #print '\\nThere is no avaliable crop in Level 1'\n",
    "\n",
    "        for k in xrange(5):\n",
    "\n",
    "            out_index = list(np.where(top_n_predictions_level2[:, k, 0] == node_names_for_level2[i])[0])\n",
    "\n",
    "            if out_index:\n",
    "                #print '\\nSelected : {}'.format(k)\n",
    "                break\n",
    "\n",
    "        if not out_index:\n",
    "            out_index = None\n",
    "        \n",
    "    #print '\\nCrop Indexes for {} :'.format(node_names_for_level2[i]), out_index\n",
    "            \n",
    "    crop_indexes_for_level2.append(out_index)\n",
    "        \n",
    "crop_indexes_for_level2 = np.array(crop_indexes_for_level2)\n",
    "\n",
    "#print '\\n--------------------------------------------------------------------------------------\\n'\n",
    "#print '\\n------------- Selected Labels for Level 1\\n\\n', node_names_for_level2\n",
    "#print '\\n------------- Crop Indexes For Level 1:\\n\\n', crop_indexes_for_level2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parent_nodes_for_level3 = []\n",
    "\n",
    "for i in xrange(len(node_names_for_level3)):\n",
    "    parent_nodes_for_level3.append(node_names_for_an_image[np.where(node_names_for_an_image[:, 2] == node_names_for_level3[i])[0]][:, 1][0])\n",
    "    \n",
    "parent_nodes_for_level3 = np.array(parent_nodes_for_level3)\n",
    "\n",
    "#print '\\nParent nodes for level3 :', parent_nodes_for_level3\n",
    "#print '\\nNode names for level3   :', node_names_for_level3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crop_indexes_for_level3 = []\n",
    "\n",
    "for i in xrange(len(node_names_for_level3)):\n",
    "    \n",
    "    #print '\\n------- LABEL : {}'.format(node_names_for_level3[i])\n",
    "    \n",
    "    avaliable_crops = crop_indexes_for_level2[np.where(node_names_for_level2 == parent_nodes_for_level3[i])[0]][0]\n",
    "    \n",
    "    if avaliable_crops != None:\n",
    "    \n",
    "        avaliable_crops_numpy = np.array(avaliable_crops)\n",
    "\n",
    "        #print '\\nAvaliable crops for {} :'.format(node_names_for_level3[i]), avaliable_crops_numpy\n",
    "\n",
    "        for k in xrange(5):\n",
    "\n",
    "            out_index = list(np.where(top_n_predictions_level3[avaliable_crops_numpy, k, 0] == node_names_for_level3[i])[0])\n",
    "\n",
    "            if out_index:\n",
    "                out_index = list(avaliable_crops_numpy[out_index])\n",
    "                #print '\\nSelected : {}'.format(k)\n",
    "                break\n",
    "\n",
    "        if not out_index:\n",
    "            out_index = None\n",
    "            \n",
    "    if avaliable_crops == None or out_index == None:\n",
    "        \n",
    "        #print '\\nThere is no avaliable crop in Level 2'\n",
    "        \n",
    "        nnfl1 = parent_nodes_for_level2[np.where(node_names_for_level2 == parent_nodes_for_level3[i])[0]]\n",
    "        \n",
    "        avaliable_crops = crop_indexes_for_level1[np.where(node_names_for_level1 == nnfl1)[0]][0]\n",
    "        \n",
    "        if avaliable_crops != None:\n",
    "            \n",
    "            avaliable_crops_numpy = np.array(avaliable_crops)\n",
    "\n",
    "            #print '\\nAvaliable crops for {} :'.format(node_names_for_level3[i]), avaliable_crops_numpy\n",
    "\n",
    "            for k in xrange(5):\n",
    "\n",
    "                out_index = list(np.where(top_n_predictions_level3[avaliable_crops_numpy, k, 0] == node_names_for_level3[i])[0])\n",
    "\n",
    "                if out_index:\n",
    "                    out_index = list(avaliable_crops_numpy[out_index])\n",
    "                    #print '\\nSelected : {}'.format(k)\n",
    "                    break\n",
    "\n",
    "            if not out_index:\n",
    "                out_index = None\n",
    "                \n",
    "        if avaliable_crops == None or out_index == None:\n",
    "            \n",
    "            #print '\\nThere is no avaliable crop in Level 1'\n",
    "\n",
    "            for k in xrange(5):\n",
    "\n",
    "                out_index = list(np.where(top_n_predictions_level3[:, k, 0] == node_names_for_level3[i])[0])\n",
    "\n",
    "                if out_index:\n",
    "                    #print '\\nSelected : {}'.format(k)\n",
    "                    break\n",
    "\n",
    "            if not out_index:\n",
    "                out_index = None\n",
    "            \n",
    "\n",
    "    #print '\\nCrop Indexes for {} :'.format(node_names_for_level3[i]), out_index\n",
    "            \n",
    "    crop_indexes_for_level3.append(out_index)\n",
    "        \n",
    "crop_indexes_for_level3 = np.array(crop_indexes_for_level3)\n",
    "\n",
    "#print '\\n--------------------------------------------------------------------------------------\\n'\n",
    "#print '\\n------------- Selected Labels for Level 3\\n\\n', node_names_for_level3\n",
    "#print '\\n------------- Crop Indexes For Level 3:\\n\\n', crop_indexes_for_level3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print '----------------------------------------\\n CLASSIFICATION RESULTS \\n----------------------------------------'\n",
    "#print_image(img_rescaled)\n",
    "#print_predictions(predictions_for_an_image[-1], 'LEVEL 3')\n",
    "\n",
    "\n",
    "#print '----------------------------------------\\n LOCALIZATION RESULTS \\n----------------------------------------'\n",
    "\n",
    "predicted_bounding_boxes_for_an_image = []\n",
    "\n",
    "for i in xrange(len(crop_indexes_for_level3)):\n",
    "    \n",
    "    #print '\\n ----------------------------- LABEL      : {} ---------------------------'.format(node_names_for_level3[i])\n",
    "    #print '\\n ----------------------------- CROP INDEX : {} ---------------------------'.format(crop_indexes_for_level3[i])\n",
    "    \n",
    "    if crop_indexes_for_level3[i] is not None:\n",
    "        bbox = np.round(np.mean(crop_positions_for_an_image[crop_indexes_for_level3[i]], axis = 0)).astype('int')\n",
    "        #for ci in crop_indexes_for_level3[i]:\n",
    "        #    print 'Crop Index : {}'.format(ci)\n",
    "        #    print_image(cropped_rescaled_images_for_an_image[ci])\n",
    "        #print '-------------------------------- MEAN -----------------------------------'\n",
    "        #print_image(img_rescaled[bbox[0] : bbox[1], bbox[2] : bbox[3]])\n",
    "        \n",
    "    else:\n",
    "        bbox = None\n",
    "        \n",
    "    predicted_bounding_boxes_for_an_image.append(bbox)\n",
    "    \n",
    "predicted_bounding_boxes_for_an_image = np.array(predicted_bounding_boxes_for_an_image)\n",
    "        \n",
    "        \n",
    "#print '----------------------------------------\\n CLASSIFICATION RESULTS \\n----------------------------------------'\n",
    "#print_image(img_rescaled)\n",
    "#print_predictions(predictions_for_an_image[-1], 'LEVEL 3')\n",
    "\n",
    "\n",
    "#print '----------------------------------------\\n LOCALIZATION RESULTS \\n----------------------------------------'\n",
    "#for i in xrange(len(crop_indexes_for_level3)):\n",
    "    \n",
    "#    print '\\n ----------------------------- LABEL      : {} ---------------------------'.format(node_names_for_level3[i])\n",
    "#    print '\\n ----------------------------- CROP INDEX : {} ---------------------------'.format(crop_indexes_for_level3[i])\n",
    "    \n",
    "#    if crop_indexes_for_level3[i] is not None:\n",
    "#        max_index = crop_indexes_for_level3[i][np.argmax(top_n_predictions_level3[crop_indexes_for_level3[i]][np.where(top_n_predictions_level3[crop_indexes_for_level3[i]] == \n",
    "#                                                                        node_names_for_level3[i])[:2]][:, 1].astype('float32'))]\n",
    "    \n",
    "#    print_image(cropped_rescaled_images_for_an_image[max_index])\n",
    "#    print '\\nCrop Position : ', crop_positions_for_an_image[max_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print predicted_bounding_boxes_for_an_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
